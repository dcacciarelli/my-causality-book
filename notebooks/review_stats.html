
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>1. Probability Theory and Statistics &#8212; Applied Causal Inference with Examples from Electricity Markets</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/review_stats';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2. Linear Regression" href="review_linear_models.html" />
    <link rel="prev" title="Applied Causal Inference for Electricity Markets" href="../intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo_applied_causal_inference.png" class="logo__image only-light" alt="Applied Causal Inference with Examples from Electricity Markets - Home"/>
    <script>document.write(`<img src="../_static/logo_applied_causal_inference.png" class="logo__image only-dark" alt="Applied Causal Inference with Examples from Electricity Markets - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Applied Causal Inference for Electricity Markets
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Crash course on Stats and ML</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">1. Probability Theory and Statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="review_linear_models.html">2. Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="review_ML.html">3. Machine Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="motivation.html">4. Motivation</a></li>
<li class="toctree-l1"><a class="reference internal" href="guide.html">5. What to expect from each chapter</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">I. Basic Concepts</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="correlation_vs_causation.html">6. Correlation vs. Causation</a></li>
<li class="toctree-l1"><a class="reference internal" href="DAG.html">7. Causal Representations</a></li>
<li class="toctree-l1"><a class="reference internal" href="basic_dag_structures.html">8. Basic Causal Structures</a></li>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">9. Definitions and Terminology</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">II. Causal Discovery</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="preface_causal_discovery.html">10. Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="semiparametric_direct_lingam.html">11. Linear Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="semiparametric_resit.html">12. Nonlinear Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="semiparametric_varlingam.html">13. Time Series Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="structural_breaks_example.html">14. Structural Breaks</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">III. Causal Inference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="preface_causal_inference.html">15. Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="instrumental_variables.html">16. Instrumental Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="propensity_scores.html">17. Propensity Score Matching</a></li>
<li class="toctree-l1"><a class="reference internal" href="double_machine_learning.html">18. Double Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="diff_in_diff.html">19. Difference-in-Differences</a></li>
<li class="toctree-l1"><a class="reference internal" href="interrupted_time_series.html">20. Interrupted Time Series</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">IV. Interpretability</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="preface_interpretability.html">21. Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="partial_dependency_plots.html">22. Partial Dependence Plots</a></li>
<li class="toctree-l1"><a class="reference internal" href="accumulated_local_effects.html">23. Accumulated Local Effects</a></li>
<li class="toctree-l1"><a class="reference internal" href="impulse_response_functions.html">24. Impulse Response Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="shapley.html">25. Shapley Additive Explanations</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">V. Experiments and Data Collection</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="preface_designs.html">26. Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="AB_testing.html">27. A/B Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="bandits.html">28. Multi-Armed Bandits</a></li>
<li class="toctree-l1"><a class="reference internal" href="design_of_experiments.html">29. Design of Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="active_learning.html">30. Active Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Other</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../bibliography.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fnotebooks/review_stats.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/review_stats.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Probability Theory and Statistics</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-concepts">1.1. Basic concepts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#expectation-variance-and-covariance">1.2. Expectation, variance, and covariance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convergence-and-estimation">1.3. Convergence and estimation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-prediction">1.4. Statistical prediction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#main-probability-distributions">1.5. Main probability distributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hypothesis-testing-framework">1.6. Hypothesis testing framework</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#markov-chain-monte-carlo-mcmc">1.7. Markov chain Monte Carlo (MCMC)</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="probability-theory-and-statistics">
<h1><span class="section-number">1. </span>Probability Theory and Statistics<a class="headerlink" href="#probability-theory-and-statistics" title="Link to this heading">#</a></h1>
<section id="basic-concepts">
<h2><span class="section-number">1.1. </span>Basic concepts<a class="headerlink" href="#basic-concepts" title="Link to this heading">#</a></h2>
<p>A <strong>random variable</strong> is a fundamental concept in probability and statistics. It represents a variable whose values are determined by the outcomes of a random phenomenon. A <strong>discrete random variable</strong> takes on a countable number of distinct values, while a <strong>continuous random variable</strong> can take any value within an interval on the real number line. Random variables are characterized by their probability distribution, which specifies the probabilities that the variable takes on each of its possible values. The key characteristics of a probability distribution are their expected value (mean) and variance.</p>
<p>A <strong>random process</strong> (or stochastic process) is a collection of random variables indexed by time or another variable, used to model systems that evolve randomly over time or space. A random process is a function that assigns a random variable to each point in a time or space domain (examples include stock market prices, weather patterns, and noise signals in electrical engineering). We can distinguish between discrete-time processes (whose indices are countable), and continuous-time processes (whose indices are an interval). We can also distinguish between stationary processes (whose statistical properties are constant over time), and nonstationary processes. A Markov process is a special type of stochastic process where the future state depends only on the current state.</p>
<p><strong>Statistical indepencence</strong> refers to the lack of a relationship between two or more random variables. More formally, we can distinguish between two types of statistical independence:</p>
<ol class="arabic simple">
<li><p><strong>Marginal independence</strong> refers to the lack of a relationship between two random variables, without considering the effect of any other variables. Mathematically, two random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are marginally independent (<span class="math notranslate nohighlight">\(X \perp Y\)</span>) if their joint probability distribution can be expressed as the product of their marginal probability
distributions, as in</p></li>
</ol>
<div class="amsmath math notranslate nohighlight" id="equation-bc5fbfa9-1d57-4cc2-8c62-e6bf5bd362c6">
<span class="eqno">(1.1)<a class="headerlink" href="#equation-bc5fbfa9-1d57-4cc2-8c62-e6bf5bd362c6" title="Permalink to this equation">#</a></span>\[\begin{equation}
    P(X, Y) = P(X)P(Y)
\end{equation}\]</div>
<ol class="arabic simple" start="2">
<li><p><strong>Conditional independence</strong> refers to the lack of a relationship between two random variables, given the value of one or more other variables. Mathematically, two random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are conditionally independent given a variable (<span class="math notranslate nohighlight">\(X \perp Y | Z\)</span>) if their conditional probability distribution satisfies</p></li>
</ol>
<div class="amsmath math notranslate nohighlight" id="equation-ac739b02-1336-4bf3-b598-ec9ac0a69803">
<span class="eqno">(1.2)<a class="headerlink" href="#equation-ac739b02-1336-4bf3-b598-ec9ac0a69803" title="Permalink to this equation">#</a></span>\[\begin{equation}
    P(X, Y | Z) = P(X | Z)P(Y | Z)
\end{equation}\]</div>
</section>
<section id="expectation-variance-and-covariance">
<h2><span class="section-number">1.2. </span>Expectation, variance, and covariance<a class="headerlink" href="#expectation-variance-and-covariance" title="Link to this heading">#</a></h2>
<p>The expectation (or expected value) of a continuous random variable <span class="math notranslate nohighlight">\(X\)</span> with probability density function <span class="math notranslate nohighlight">\(p(x)\)</span> is</p>
<div class="amsmath math notranslate nohighlight" id="equation-f082b720-a602-4b37-83e9-9782006dfda1">
<span class="eqno">(1.3)<a class="headerlink" href="#equation-f082b720-a602-4b37-83e9-9782006dfda1" title="Permalink to this equation">#</a></span>\[\begin{equation}
    \mathbb{E}[X] = \int xp(x)dx
\end{equation}\]</div>
<p>while the expectation of a discrete random variable with probability mass function <span class="math notranslate nohighlight">\(p(x)\)</span> is</p>
<div class="amsmath math notranslate nohighlight" id="equation-2fae78ee-60b2-49df-9795-05072c5aa333">
<span class="eqno">(1.4)<a class="headerlink" href="#equation-2fae78ee-60b2-49df-9795-05072c5aa333" title="Permalink to this equation">#</a></span>\[\begin{equation}
    \mathbb{E}[X] = \sum_{x} xp(x)
\end{equation}\]</div>
<p>The expectation of any function of a random variable, <span class="math notranslate nohighlight">\(f(X)\)</span>, is given by</p>
<div class="amsmath math notranslate nohighlight" id="equation-a9cb2cdd-5b81-4f82-9be6-ee55a4cbef49">
<span class="eqno">(1.5)<a class="headerlink" href="#equation-a9cb2cdd-5b81-4f82-9be6-ee55a4cbef49" title="Permalink to this equation">#</a></span>\[\begin{equation}
    \mathbb{E}[X] = \int f(x)p(x)dx
\end{equation}\]</div>
<p>The deviation or fluctuation of <span class="math notranslate nohighlight">\(X\)</span> from its expected value is <span class="math notranslate nohighlight">\(X - \mathbb{E}[X]\)</span>. The variance of a random variable <span class="math notranslate nohighlight">\(X\)</span> measures the dispersion around its mean, and it is given by</p>
<div class="amsmath math notranslate nohighlight" id="equation-7e188546-3b17-4cbd-8862-815ce2fbba52">
<span class="eqno">(1.6)<a class="headerlink" href="#equation-7e188546-3b17-4cbd-8862-815ce2fbba52" title="Permalink to this equation">#</a></span>\[\begin{equation}
    \operatorname{Var}[X] = \mathbb{E}[(X - \mathbb{E}[X])^2]
\end{equation}\]</div>
<p>The covariance of two random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> measures the degree to which two random variables change together. If the variables tend to show similar behavior (they tend to be above or below their expected values together), the covariance is positive. If one variable tends to increase when the other decreases, the covariance is negative. It is given by</p>
<div class="amsmath math notranslate nohighlight" id="equation-823d09f4-cbe6-41ee-8ee2-be728ce06dd8">
<span class="eqno">(1.7)<a class="headerlink" href="#equation-823d09f4-cbe6-41ee-8ee2-be728ce06dd8" title="Permalink to this equation">#</a></span>\[\begin{equation}
    \operatorname{Cov}[X,Y] = \mathbb{E}[(X - \mathbb{E}[X])(Y - \mathbb{E}[Y])]
\end{equation}\]</div>
<p>Some <strong>algebraic properties</strong> of expectation, variance, and covariance will be extremely useful in manipulating and deriving statistical quantities of interest:</p>
<ul>
<li><p><strong>Linearity of expectations</strong>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-bf2fd603-20cd-4e37-a133-da6baa2e708f">
<span class="eqno">(1.8)<a class="headerlink" href="#equation-bf2fd603-20cd-4e37-a133-da6baa2e708f" title="Permalink to this equation">#</a></span>\[\begin{equation}
        \mathbb{E}[aX+bY] = a\mathbb{E}[X] + b\mathbb{E}[Y]
    \end{equation}\]</div>
<p>Expectation is a linear operator. The expectation of a sum of random variables is the sum of their expectations, and the expectation of a scaled random variable is the scale factor times the expectation of the variable.</p>
</li>
<li><p><strong>Variance identity</strong>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-52747f4a-81d6-4900-83aa-2a14f09cf6e4">
<span class="eqno">(1.9)<a class="headerlink" href="#equation-52747f4a-81d6-4900-83aa-2a14f09cf6e4" title="Permalink to this equation">#</a></span>\[\begin{equation}
        \operatorname{Var}[X] = \mathbb{E}[(X-\mathbb{E}[X])^2] = \mathbb{E}[X^2]-(\mathbb{E}[X])^2
    \end{equation}\]</div>
<p>Expanding <span class="math notranslate nohighlight">\(\mathbb{E}[(X-\mathbb{E}[X])^2]\)</span> we get <span class="math notranslate nohighlight">\(\mathbb{E}[X^2 -2X \mathbb{E}[X] + (\mathbb{E}[X])^2]\)</span>, which is equal to <span class="math notranslate nohighlight">\(\mathbb{E}[X^2] -2\mathbb{E}[X \mathbb{E}[X]] + \mathbb{E}[(\mathbb{E}[X])^2]\)</span>. However, <span class="math notranslate nohighlight">\(\mathbb{E}[X]\)</span> is a constant (because it is the expected value of a random variable, it is not random anymore), so <span class="math notranslate nohighlight">\(\mathbb{E}[\mathbb{E}[X]]\)</span> is just <span class="math notranslate nohighlight">\(\mathbb{E}[X]\)</span>. So that becomes <span class="math notranslate nohighlight">\(\mathbb{E}[X^2] -2\mathbb{E}[X] \mathbb{E}[X] + (\mathbb{E}[X])^2 = \mathbb{E}[X^2] -2(\mathbb{E}[X])^2 + (\mathbb{E}[X])^2\)</span>.</p>
</li>
<li><p><strong>Covariance identity</strong>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-f41f1c2c-dc5e-493c-bac3-2b158d731f66">
<span class="eqno">(1.10)<a class="headerlink" href="#equation-f41f1c2c-dc5e-493c-bac3-2b158d731f66" title="Permalink to this equation">#</a></span>\[\begin{equation}
        \operatorname{Cov}[X,Y] = \mathbb{E}[(X - \mathbb{E}[X])(Y - \mathbb{E}[Y])] = \mathbb{E}[XY]-\mathbb{E}[X]\mathbb{E}[Y]
    \end{equation}\]</div>
<p>Expanding the product <span class="math notranslate nohighlight">\((X - \mathbb{E}[X])(Y - \mathbb{E}[Y])\)</span> we get <span class="math notranslate nohighlight">\(X - X\mathbb{E}[Y] - Y\mathbb{E}[X] + \mathbb{E}[X]\mathbb{E}[Y]\)</span>. Taking the expectation  we get <span class="math notranslate nohighlight">\(\mathbb{E}[XY] - \mathbb{E}[X\mathbb{E}[Y]] - \mathbb{E}[Y\mathbb{E}[X]] + \mathbb{E}[\mathbb{E}[X]\mathbb{E}[Y]]\)</span>. Because the expectation is constant, we get to <span class="math notranslate nohighlight">\(\mathbb{E}[XY] - \mathbb{E}[X]\mathbb{E}[Y] - \mathbb{E}[Y]\mathbb{E}[X] + \mathbb{E}[X]\mathbb{E}[Y]\)</span>.</p>
</li>
<li><p><strong>Covariance is symmetric</strong>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-fa591475-6d5d-41dc-addb-ebbc46a797b3">
<span class="eqno">(1.11)<a class="headerlink" href="#equation-fa591475-6d5d-41dc-addb-ebbc46a797b3" title="Permalink to this equation">#</a></span>\[\begin{equation}
        \operatorname{Cov}[X,Y] = \operatorname{Cov}[Y,X]
    \end{equation}\]</div>
<p>The direction of comparison does not matter for covariance, whether you measure how <span class="math notranslate nohighlight">\(X\)</span> varies with <span class="math notranslate nohighlight">\(Y\)</span> or <span class="math notranslate nohighlight">\(Y\)</span> with <span class="math notranslate nohighlight">\(X\)</span>, the result is the same.</p>
</li>
<li><p><strong>Variance is covariance with itself</strong>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-ad0c7d6b-9515-4b34-b4bf-0ab7593130ab">
<span class="eqno">(1.12)<a class="headerlink" href="#equation-ad0c7d6b-9515-4b34-b4bf-0ab7593130ab" title="Permalink to this equation">#</a></span>\[\begin{equation}
        \operatorname{Cov}[X,X] = \operatorname{Var}[X]
    \end{equation}\]</div>
<p>Covariance measures how two variables vary together, and variance is a special case where these two variables are the same.</p>
</li>
<li><p><strong>Variance is not linear</strong>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-c928e502-581b-45ae-acc5-4d85f8aeeb22">
<span class="eqno">(1.13)<a class="headerlink" href="#equation-c928e502-581b-45ae-acc5-4d85f8aeeb22" title="Permalink to this equation">#</a></span>\[\begin{equation}
        \operatorname{Var}[aX + b] = a^2\operatorname{Var}[X]
    \end{equation}\]</div>
<p>The square in the variance formula leads to a squared scale factor when a random variable is scaled. The addition of a constant <span class="math notranslate nohighlight">\(b\)</span> does not affect variance, as variance measures dispersion around the mean, which is unaffected by constant shifts. To show why <span class="math notranslate nohighlight">\(a\)</span> becomes <span class="math notranslate nohighlight">\(a^2\)</span>, we have <span class="math notranslate nohighlight">\(\operatorname{Var}[aX] = \mathbb{E}[(aX-\mathbb{E}(aX)^2]\)</span>, which is equal to <span class="math notranslate nohighlight">\(\mathbb{E}[a^2(X-\mathbb{E}(X)^2] = a^2\mathbb{E}[(X-\mathbb{E}(X)^2]\)</span>.</p>
</li>
<li><p><strong>Covariance is not linear</strong>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-d3904559-ccf6-4f5b-96b8-94a4d62fd28e">
<span class="eqno">(1.14)<a class="headerlink" href="#equation-d3904559-ccf6-4f5b-96b8-94a4d62fd28e" title="Permalink to this equation">#</a></span>\[\begin{equation}
        \operatorname{Cov}[aX + b,Y] = a\operatorname{Cov}[X,Y]
    \end{equation}\]</div>
<p>Scaling one variable in a covariance relationship scales the covariance itself but does not affect the relationship’s direction or absence (signified by zero covariance). The addition of a constant does not affect covariance, as it does not change how one variable varies with another.</p>
</li>
<li><p><strong>Variance of a sum</strong>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-174230f2-7293-4034-8cef-3086188c63fc">
<span class="eqno">(1.15)<a class="headerlink" href="#equation-174230f2-7293-4034-8cef-3086188c63fc" title="Permalink to this equation">#</a></span>\[\begin{equation}
        \operatorname{Var}[X+Y] = \operatorname{Var}[X] + \operatorname{Var}[Y] + 2\operatorname{Cov}[X,Y]
    \end{equation}\]</div>
<p>The variance of a sum includes the individual variances and an additional term to account for how the variables co-vary. This comes from expanding <span class="math notranslate nohighlight">\(\mathbb{E}[(X + Y - \mathbb{E}[X+Y])^2]\)</span> and using the linearity of expectations.</p>
</li>
<li><p><strong>Variance of a large sum</strong>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-3fbb2272-2f38-422f-b5b9-e0cb9314cb56">
<span class="eqno">(1.16)<a class="headerlink" href="#equation-3fbb2272-2f38-422f-b5b9-e0cb9314cb56" title="Permalink to this equation">#</a></span>\[\begin{equation}
        \operatorname{Var}\left[ \sum_{i=1}^{n}X_i \right] = \sum_{i=1}^{n}\sum_{j=1}^{n}\operatorname{Cov}[X_i,X_j] = \sum_{i=1}^{n}\operatorname{Var}[X_i] + 2\sum_{i=1}^{n-1}\sum_{j&gt;i}\operatorname{Cov}[X_i,X_j]
    \end{equation}\]</div>
<p>The variance of a sum of multiple random variables includes both their individual variances and the covariance terms for every pair.</p>
</li>
<li><p><strong>Law of total expectations</strong>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-81c39488-37e2-4e57-9dff-4b6c21b0f7f8">
<span class="eqno">(1.17)<a class="headerlink" href="#equation-81c39488-37e2-4e57-9dff-4b6c21b0f7f8" title="Permalink to this equation">#</a></span>\[\begin{equation}
        \mathbb{E}[X] = \mathbb{E}[\mathbb{E}[X|Y]]
    \end{equation}\]</div>
<p>Suppose we have two random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>. We want to express the expectation of <span class="math notranslate nohighlight">\(X\)</span> (a marginal expectation) in terms of its conditional expectation given <span class="math notranslate nohighlight">\(Y\)</span>. his law states that the overall expectation of <span class="math notranslate nohighlight">\(X\)</span> can be found by taking the expectation of the conditional expectation of <span class="math notranslate nohighlight">\(X\)</span> given <span class="math notranslate nohighlight">\(Y\)</span>. In practice, what we are doing is splitting the entire probability space into parts based on the values of <span class="math notranslate nohighlight">\(Y\)</span>, calculating the expected value of <span class="math notranslate nohighlight">\(X\)</span> (this is <span class="math notranslate nohighlight">\(\mathbb{E}[X|Y]\)</span>), and then taking the expectation of these conditional expectations over the distribution of <span class="math notranslate nohighlight">\(Y\)</span>. Imagine <span class="math notranslate nohighlight">\(Y\)</span> as categorizing or segmenting the probability space into different scenarios or groups. Within each group, you calculate the average value of <span class="math notranslate nohighlight">\(X\)</span> (this gives you <span class="math notranslate nohighlight">\(\mathbb{E}[X|Y=y]\)</span> for each <span class="math notranslate nohighlight">\(y\)</span>). Then, you average these averages over all possible groups (weighted by the probability of each group <span class="math notranslate nohighlight">\(Y=y\)</span>, leading back to the overall average of <span class="math notranslate nohighlight">\(X\)</span>. This law is particularly useful in scenarios where direct calculation of <span class="math notranslate nohighlight">\(\mathbb{E}[X]\)</span> is complex but where conditional expectations <span class="math notranslate nohighlight">\(\mathbb{E}[X|Y]\)</span> are simpler to compute.
This is the expected value (or mean) of <span class="math notranslate nohighlight">\(X\)</span> given a particular value of <span class="math notranslate nohighlight">\(Y\)</span>. In many statistical models, especially in predictive modeling, this conditional mean can be thought of as a ``prediction’’ of  <span class="math notranslate nohighlight">\(X\)</span> based on the knowledge of <span class="math notranslate nohighlight">\(Y\)</span>. For example, if <span class="math notranslate nohighlight">\(Y\)</span> represents a set of features or conditions, then <span class="math notranslate nohighlight">\(\mathbb{E}[X|Y]\)</span> is our best guess or prediction of <span class="math notranslate nohighlight">\(X\)</span> under those conditions.</p>
</li>
<li><p><strong>Law of total variance</strong>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-9070076d-98ac-4553-afaa-1879893cc150">
<span class="eqno">(1.18)<a class="headerlink" href="#equation-9070076d-98ac-4553-afaa-1879893cc150" title="Permalink to this equation">#</a></span>\[\begin{equation}
        \operatorname{Var}[X] = \operatorname{Var}[\mathbb{E}[X|Y]] + \mathbb{E}[\operatorname{Var}[X|Y]]
    \end{equation}\]</div>
<p>This law decomposes the total variance into two parts. The first part can be thought of as between-group variability and measures how much the conditional means vary as <span class="math notranslate nohighlight">\(Y\)</span> changes. The second term is the within-group variability and represents the average of the variances within each group defined by <span class="math notranslate nohighlight">\(Y\)</span>.</p>
</li>
<li><p><strong>Independence implies zero covariance</strong>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-4136127e-45f4-47a7-ad7c-0fa76ad00e37">
<span class="eqno">(1.19)<a class="headerlink" href="#equation-4136127e-45f4-47a7-ad7c-0fa76ad00e37" title="Permalink to this equation">#</a></span>\[\begin{equation}
        X \perp Y \rightarrow \operatorname{Cov}[X,Y] = 0
    \end{equation}\]</div>
<p>Independence between two variables means the occurrence of one does not affect the probability distribution of the other. This lack of influence translates mathematically to zero covariance. However, the converse is not necessarily true as zero covariance does not capture nonlinear dependencies.</p>
</li>
</ul>
</section>
<section id="convergence-and-estimation">
<h2><span class="section-number">1.3. </span>Convergence and estimation<a class="headerlink" href="#convergence-and-estimation" title="Link to this heading">#</a></h2>
<p>The <strong>law of large numbers (LLN)</strong> states that, for a sequence of independent and identically distributed (i.i.d.) random variables <span class="math notranslate nohighlight">\(X_1, X_2 \ldots, X_n\)</span> each with expected value <span class="math notranslate nohighlight">\(\mathbb{E}[X]\)</span>, the sample mean converges to the expected value as <span class="math notranslate nohighlight">\(n\)</span> approaches infinity</p>
<div class="amsmath math notranslate nohighlight" id="equation-dd1b4d62-43e1-4914-a5ee-3ed8df5ac20e">
<span class="eqno">(1.20)<a class="headerlink" href="#equation-dd1b4d62-43e1-4914-a5ee-3ed8df5ac20e" title="Permalink to this equation">#</a></span>\[\begin{equation}
    \frac{1}{n}\sum_{i=1}^{n}X_i \rightarrow \mathbb{E}[X] \quad \text{ as } n \rightarrow \infty
\end{equation}\]</div>
<p>The <strong>i.i.d. assumption</strong> is a fundamental concept in probability theory and statistics, with significant implications. Independence implies that the occurrence of one event or the value of one variable does not influence the occurrence of another. In the context of random variables, <span class="math notranslate nohighlight">\(X_1, X_2 \ldots, X_n\)</span> being independent means the outcome of <span class="math notranslate nohighlight">\(X_i\)</span> provides no information about the outcome of <span class="math notranslate nohighlight">\(X_j\)</span>, <span class="math notranslate nohighlight">\(i\neq j\)</span>. Identically distributed means that each of the random variables has the same probability distribution. They do not need to take on the same value, but the rules governing their behavior (i.e., the likelihood of each outcome) are identical. In the context of supervised learning, the i.i.d. assumption assumes that the training and test data are independently drawn from the same underlying probability distribution. This enables the use of statistical tools and techniques, such as maximum likelihood estimation and hypothesis testing, which are based on the assumption of independent and identically distributed data. In real-world data, this assumption is often violated as data may be dependent and non-identically distributed due to distribution shifts across geography or time, sampling practices, or the presence of confounding variables and selection bias.</p>
<p>The <strong>central limit theorem (CLT)</strong> states that if <span class="math notranslate nohighlight">\(X_1, X_2, \ldots, X_n\)</span> are i.i.d. random variables with an expected value <span class="math notranslate nohighlight">\(\mathbb{E}[X]\)</span> and a finite variance <span class="math notranslate nohighlight">\(\operatorname{Var}[X]\)</span>, the distribution of the sample mean</p>
<div class="amsmath math notranslate nohighlight" id="equation-cacf2313-cf3a-4adb-bab2-e51f1ccd16fc">
<span class="eqno">(1.21)<a class="headerlink" href="#equation-cacf2313-cf3a-4adb-bab2-e51f1ccd16fc" title="Permalink to this equation">#</a></span>\[\begin{equation}
    \bar{X}_n = \frac{1}{n} \sum_{i=1}^{n} X_i
\end{equation}\]</div>
<p>approaches a normal distribution as <span class="math notranslate nohighlight">\(n \rightarrow \infty\)</span>. Specifically, the standardized form</p>
<div class="amsmath math notranslate nohighlight" id="equation-3b068912-f2ac-43a1-bc60-44ce15d4c708">
<span class="eqno">(1.22)<a class="headerlink" href="#equation-3b068912-f2ac-43a1-bc60-44ce15d4c708" title="Permalink to this equation">#</a></span>\[\begin{equation}
    \frac{\bar{X}_n - \mathbb{E}[X]}{\sqrt{\operatorname{Var}[X]/n}}
\end{equation}\]</div>
<p>approaches the standard normal distribution <span class="math notranslate nohighlight">\(N(0, 1)\)</span>.</p>
<p>The motivation behind the CLT lies in its ability to provide a predictable and well-understood behavior (the normal distribution) for averages of random variables, regardless of the original distribution of these variables. This is particularly useful in practical scenarios such as statistical sampling and hypothesis testing, where it is often necessary to make inferences about population parameters. The intuition of the CLT is that as we increase the number of random variables in our sample, the peculiarities and individual randomness of each variable tend to cancel out. This leads to the emergence of the normal distribution, which is symmetric and centered around the mean. The CLT is powerful because it applies to a wide range of distributions, whether they are symmetric, skewed, or even arbitrary, as long as the variables are i.i.d. with a finite variance.</p>
<p><strong>Estimation</strong></p>
<p>When observing values <span class="math notranslate nohighlight">\(X_1, X_2, \ldots, X_n\)</span> from a distribution, the true nature of this distribution is often unknown. It is usually characterized by a function with one or more unknown parameters, denoted as <span class="math notranslate nohighlight">\(f(x; \theta)\)</span>. Some key terminology in statistics and estimation are:</p>
<ul class="simple">
<li><p><strong>Statistic</strong>: a function of the observed data, or the data alone.</p></li>
<li><p><strong>Estimator</strong>: a rule or a function that tells you how to infer or guess the value of a parameter <span class="math notranslate nohighlight">\(\theta\)</span>, or some function of it, denoted as <span class="math notranslate nohighlight">\(h(\theta)\)</span>. Suppose you want to estimate the population mean. The sample mean (denoted usually as <span class="math notranslate nohighlight">\(\bar{X}\)</span>) is an estimator. It is a function that calculates the mean of your sample data.</p></li>
<li><p><strong>Estimand</strong>: the quantity that we want to estimate.</p></li>
<li><p><strong>Estimate</strong>: the actual numerical value obtained by applying the estimator to your data. It is an approximation of some estimand, which we get using data.</p></li>
</ul>
<p>We typically denote an estimator of <span class="math notranslate nohighlight">\(\theta\)</span> as <span class="math notranslate nohighlight">\(\widehat{\theta}_n\)</span>, where the hat symbol signifies that it is an estimate of the true parameter, and the subscript <span class="math notranslate nohighlight">\(n\)</span> indicates its dependence on the sample size. An estimator is itself a random variable because it is a function of random data. Its distribution, known as the sampling distribution, depends on the distribution of the data <span class="math notranslate nohighlight">\(X_i\)</span>. A key property of an estimator is consistency, which means that <span class="math notranslate nohighlight">\(\hat{\theta}_n\)</span> converges to <span class="math notranslate nohighlight">\(\theta\)</span> as <span class="math notranslate nohighlight">\(n \rightarrow \infty\)</span>. An estimator that fails to be consistent is generally not desirable. Another important aspect is the bias of an estimator, defined as <span class="math notranslate nohighlight">\(\mathbb{E}[\hat{\theta}_n - \theta]\)</span>. An estimator is unbiased if its bias is zero for all <span class="math notranslate nohighlight">\(\theta\)</span>. The estimator also has a variance, denoted as <span class="math notranslate nohighlight">\(\operatorname{Var}[\hat{\theta}]\)</span>. The square root of this variance is called the standard error, which provides a measure of how precise our estimate is.</p>
</section>
<section id="statistical-prediction">
<h2><span class="section-number">1.4. </span>Statistical prediction<a class="headerlink" href="#statistical-prediction" title="Link to this heading">#</a></h2>
<p><strong>Predicting one random variable from its distribution</strong></p>
<p>Suppose we want to guess the value of a random variable <span class="math notranslate nohighlight">\(Y\)</span>. If we have a prediction that the value is going to be <span class="math notranslate nohighlight">\(m\)</span>, how do we assess the quality of our prediction? Ideally, we would like the difference between <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(m\)</span> to be as small as possible. Since we do not care if the difference is positive or negative, a common way to assess the quality of the prediction is to look at the squared error <span class="math notranslate nohighlight">\((Y-m)^2\)</span>. Now, because <span class="math notranslate nohighlight">\(Y\)</span> is a random value, it will fluctuate. So, we look at the mean square error (MSE) of <span class="math notranslate nohighlight">\(m\)</span>, which is the expected value of the squared differences, as in</p>
<div class="amsmath math notranslate nohighlight" id="equation-14649c7d-6005-404f-b6c1-dd788d1549ae">
<span class="eqno">(1.23)<a class="headerlink" href="#equation-14649c7d-6005-404f-b6c1-dd788d1549ae" title="Permalink to this equation">#</a></span>\[\begin{align}
    \text{MSE}(m) &amp;= \mathbb{E}[(Y-m)^2] \\
    &amp;= \mathbb{E}[Y^2] - 2m \mathbb{E}[Y] + m^2
\end{align}\]</div>
<p>Where we considered that <span class="math notranslate nohighlight">\(m\)</span> is a constant and not a random variable (<span class="math notranslate nohighlight">\(\mathbb{E}[m]=m\)</span>). Now, recall from the variance identity that <span class="math notranslate nohighlight">\(\operatorname{Var}[X] = \mathbb{E}[(X-\mathbb{E}[X])^2] = \mathbb{E}[X^2]-(\mathbb{E}[X])^2\)</span>. If we replace <span class="math notranslate nohighlight">\(X\)</span> with <span class="math notranslate nohighlight">\(Y-m\)</span>, we have that</p>
<div class="amsmath math notranslate nohighlight" id="equation-6be5404d-97c6-4b08-a276-802e9448727b">
<span class="eqno">(1.24)<a class="headerlink" href="#equation-6be5404d-97c6-4b08-a276-802e9448727b" title="Permalink to this equation">#</a></span>\[\begin{align}
    \operatorname{Var}[Y-m] &amp;= \mathbb{E}[(Y-m)^2]-(\mathbb{E}[Y-m])^2 \\
    &amp;= \mathbb{E}[Y^2] - 2m \mathbb{E}[Y] + m^2 -(\mathbb{E}[Y-m])^2 \\
    &amp;= \text{MSE}(m) -(\mathbb{E}[Y-m])^2
\end{align}\]</div>
<p>Thus, remembering that <span class="math notranslate nohighlight">\(\operatorname{Var}[Y-m] = \operatorname{Var}[Y]\)</span> and that <span class="math notranslate nohighlight">\(\mathbb{E}[m]=m\)</span> we can express the MSE of <span class="math notranslate nohighlight">\(m\)</span> as</p>
<div class="amsmath math notranslate nohighlight" id="equation-2452bab6-e1bb-412e-89fc-81abcd008d59">
<span class="eqno">(1.25)<a class="headerlink" href="#equation-2452bab6-e1bb-412e-89fc-81abcd008d59" title="Permalink to this equation">#</a></span>\[\begin{align}
    \text{MSE}(m) &amp;= (\mathbb{E}[Y-m])^2 + \operatorname{Var}[Y] \\
    &amp;= (\mathbb{E}[Y]-m)^2 + \operatorname{Var}[Y]
\end{align}\]</div>
<p>This is the simplest form of bias-variance decomposition: the first term is the squared bias of estimating <span class="math notranslate nohighlight">\(Y\)</span> with <span class="math notranslate nohighlight">\(m\)</span>; the second term is the variance of <span class="math notranslate nohighlight">\(Y-m\)</span>. To find the best prediction <span class="math notranslate nohighlight">\(m\)</span> for <span class="math notranslate nohighlight">\(Y\)</span>, we now aim to minimize the MSE. However, we can ignore the second component of the MSE, as the variance term <span class="math notranslate nohighlight">\(\text{Var}[Y]\)</span> does not depend on the prediction <span class="math notranslate nohighlight">\(m\)</span>, as it is a characteristic of the distribution of <span class="math notranslate nohighlight">\(Y\)</span>. Hence, it does not affect the minimization process with respect to <span class="math notranslate nohighlight">\(m\)</span>.To minimize <span class="math notranslate nohighlight">\(MSE(m)\)</span>, we take its derivative with respect to <span class="math notranslate nohighlight">\(m\)</span></p>
<div class="amsmath math notranslate nohighlight" id="equation-772ecc02-cd48-49ba-8d38-19646613d0b5">
<span class="eqno">(1.26)<a class="headerlink" href="#equation-772ecc02-cd48-49ba-8d38-19646613d0b5" title="Permalink to this equation">#</a></span>\[\begin{align}
    \frac{d\text{MSE}(m)}{dm} &amp;= \frac{d}{dm} \left[(\mathbb{E}[Y] - m)^2 + \text{Var}[Y] \right] \\
    &amp;= 2(\mathbb{E}[Y] - m)\left(\frac{d\mathbb{E}[Y]}{dm}- \frac{dm}{dm} \right) + \frac{d\text{Var}[Y]}{dm} 
\end{align}\]</div>
<p>Since <span class="math notranslate nohighlight">\(\text{Var}[Y]\)</span> and <span class="math notranslate nohighlight">\(\mathbb{E}[Y]\)</span> are constant with respect to <span class="math notranslate nohighlight">\(m\)</span>, their derivative is zero (changing <span class="math notranslate nohighlight">\(m\)</span> does not affect the distribution of <span class="math notranslate nohighlight">\(Y\)</span>). So we can simplify the overall derivative to</p>
<div class="amsmath math notranslate nohighlight" id="equation-ca88ca0c-dd71-4f07-8c74-2e08ad1aacce">
<span class="eqno">(1.27)<a class="headerlink" href="#equation-ca88ca0c-dd71-4f07-8c74-2e08ad1aacce" title="Permalink to this equation">#</a></span>\[\begin{equation}
    \frac{d\text{MSE}(m)}{dm} = -2(\mathbb{E}[Y] - m)
\end{equation}\]</div>
<p>Setting this derivative to zero for minimization we obtain</p>
<div class="amsmath math notranslate nohighlight" id="equation-6fb938ab-e8ec-41ab-929a-0c08b17aa85b">
<span class="eqno">(1.28)<a class="headerlink" href="#equation-6fb938ab-e8ec-41ab-929a-0c08b17aa85b" title="Permalink to this equation">#</a></span>\[\begin{equation}
    -2(\mathbb{E}[Y] - m) = 0 \quad \longrightarrow \quad m = \mathbb{E}[Y]
\end{equation}\]</div>
<p>Thus, the best single-number prediction for minimizing the MSE, or the optimal guess for <span class="math notranslate nohighlight">\(Y\)</span>, is its expected value <span class="math notranslate nohighlight">\(\mathbb{E}[Y]\)</span>.</p>
<p><strong>Predicting one random variable from another</strong></p>
<p>Let us now suppose we want to predict the value of <span class="math notranslate nohighlight">\(Y\)</span>, but we can use the knowledge about another random variable <span class="math notranslate nohighlight">\(X\)</span>. Now, our guess is <span class="math notranslate nohighlight">\(m(X)\)</span>, a function of <span class="math notranslate nohighlight">\(X\)</span>. The error that we would now like to minimize is represented by <span class="math notranslate nohighlight">\(\mathbb{E}[(Y-m(x))^2]\)</span>. From the law of total expectations, we know that <span class="math notranslate nohighlight">\(\mathbb{E}[X] = \mathbb{E}[\mathbb{E}[X|Y]]\)</span>. Replacing <span class="math notranslate nohighlight">\(X\)</span> with <span class="math notranslate nohighlight">\((Y-m(x))^2\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> with <span class="math notranslate nohighlight">\(X\)</span> we obtain</p>
<div class="amsmath math notranslate nohighlight" id="equation-e53a1006-79a9-4032-9aff-97bf8fe8ac07">
<span class="eqno">(1.29)<a class="headerlink" href="#equation-e53a1006-79a9-4032-9aff-97bf8fe8ac07" title="Permalink to this equation">#</a></span>\[\begin{equation}
    \mathbb{E}[(Y-m(x))^2] = \mathbb{E}[\mathbb{E}[(Y-m(x))^2|X]]
\end{equation}\]</div>
<p>where we express the MSE as an expectation of conditional expectations. For each value of <span class="math notranslate nohighlight">\(X=x\)</span>, the best prediction for <span class="math notranslate nohighlight">\(Y\)</span> (in terms of minimizing the MSE) is the conditional mean <span class="math notranslate nohighlight">\(\mathbb{E}[Y|X=x]\)</span>. Thus, the optimal prediction function is</p>
<div class="amsmath math notranslate nohighlight" id="equation-2fcf2409-d428-4a25-8b13-a5ef64cc8d1f">
<span class="eqno">(1.30)<a class="headerlink" href="#equation-2fcf2409-d428-4a25-8b13-a5ef64cc8d1f" title="Permalink to this equation">#</a></span>\[\begin{equation}
    m^*(X) = \mathbb{E}[Y|X=x]
\end{equation}\]</div>
<p>which is known as the regression function of <span class="math notranslate nohighlight">\(Y\)</span> on <span class="math notranslate nohighlight">\(X\)</span>, and describes how the expected value of <span class="math notranslate nohighlight">\(Y\)</span> changes with <span class="math notranslate nohighlight">\(X\)</span>. In general, the true regression function can be quite complex and may not have a simple mathematical expression. Due to this complexity, simpler models (like linear regression) are often used as approximations.</p>
</section>
<section id="main-probability-distributions">
<h2><span class="section-number">1.5. </span>Main probability distributions<a class="headerlink" href="#main-probability-distributions" title="Link to this heading">#</a></h2>
<p><strong>Normal distribution</strong></p>
<p>The normal distribution, also known as the Gaussian distribution, is central in statistics due to its symmetric, bell-shaped curve. It is characterized by its mean <span class="math notranslate nohighlight">\( \mu \)</span> and standard deviation <span class="math notranslate nohighlight">\( \sigma \)</span>, with the probability density function (PDF) given by</p>
<div class="amsmath math notranslate nohighlight" id="equation-2f0f8f7f-e96c-4e7b-89b5-8727c084db90">
<span class="eqno">(1.31)<a class="headerlink" href="#equation-2f0f8f7f-e96c-4e7b-89b5-8727c084db90" title="Permalink to this equation">#</a></span>\[\begin{equation}
    f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
\end{equation}\]</div>
<p>The significance of the normal distribution arises from the CLT, which states that sums of independent random variables converge to a normal distribution, regardless of the original distribution of these variables, making it applicable in a wide array of scenarios. This property underscores the normal distribution’s role in approximating the behavior of various real-world random processes.</p>
<p><strong>Chi-Squared distribution</strong></p>
<p>The chi-squared distribution is another key distribution in statistics, especially in hypothesis testing and confidence interval estimation. It arises as the sum of the squares of independent standard normal variables. Specifically, if <span class="math notranslate nohighlight">\( Z_1, Z_2, ..., Z_k \)</span> are independent standard normal random variables, then <span class="math notranslate nohighlight">\( \sum_{i=1}^{k} Z_i^2 \)</span> follows a chi-squared distribution with <span class="math notranslate nohighlight">\( k \)</span> degrees of freedom. Its PDF for <span class="math notranslate nohighlight">\( x &gt; 0 \)</span> and <span class="math notranslate nohighlight">\( k \)</span> degrees of freedom is</p>
<div class="amsmath math notranslate nohighlight" id="equation-e826f442-48ad-4fe1-bf58-92b599ef9659">
<span class="eqno">(1.32)<a class="headerlink" href="#equation-e826f442-48ad-4fe1-bf58-92b599ef9659" title="Permalink to this equation">#</a></span>\[\begin{equation}
    f(x;k) = \frac{x^{k/2-1}e^{-x/2}}{2^{k/2}\Gamma(k/2)}
\end{equation}\]</div>
<p>This distribution is asymmetric and skewed to the right, with its shape and spread depending on the degrees of freedom <span class="math notranslate nohighlight">\( k \)</span>. It is primarily used in the chi-squared test for independence and goodness of fit, and in estimating variances of normal distributions.</p>
<p><strong>F-distribution</strong></p>
<p>The F-distribution is crucial in the context of variance analysis and hypothesis testing. It is the ratio of two scaled chi-squared distributions: if <span class="math notranslate nohighlight">\( U \)</span> follows a chi-squared distribution with <span class="math notranslate nohighlight">\( d_1 \)</span> degrees of freedom and <span class="math notranslate nohighlight">\( V \)</span> follows an independent chi-squared distribution with <span class="math notranslate nohighlight">\( d_2 \)</span> degrees of freedom, then the ratio <span class="math notranslate nohighlight">\( \frac{U/d_1}{V/d_2} \)</span> follows an F-distribution. Its PDF is described by</p>
<div class="amsmath math notranslate nohighlight" id="equation-3ce8032b-a662-4ff1-a416-c46d99fde96d">
<span class="eqno">(1.33)<a class="headerlink" href="#equation-3ce8032b-a662-4ff1-a416-c46d99fde96d" title="Permalink to this equation">#</a></span>\[\begin{equation}
    f(x; d_1, d_2) = \frac{\sqrt{\frac{(d_1x)^{d_1}d_2^{d_2}}{(d_1x+d_2)^{d_1+d_2}}}}{x\text{B}\left(\frac{d_1}{2},\frac{d_2}{2}\right)}
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\( d_1 \)</span> and <span class="math notranslate nohighlight">\( d_2 \)</span> are the degrees of freedom. The distribution is non-symmetric, bounded at the left by 0, and its shape varies with the degrees of freedom. It is particularly useful in comparing variances between two samples, as in ANOVA and regression analysis.</p>
<p><strong>Student’s t-distribution</strong></p>
<p>The Student’s t-distribution arises when estimating the mean of a normally distributed population in situations where the sample size is small and the population standard deviation is unknown. It is defined by the PDF</p>
<div class="amsmath math notranslate nohighlight" id="equation-0ed4016c-314e-4d73-a6c2-fe0c29151e65">
<span class="eqno">(1.34)<a class="headerlink" href="#equation-0ed4016c-314e-4d73-a6c2-fe0c29151e65" title="Permalink to this equation">#</a></span>\[\begin{equation}
    f(t) = \frac{\Gamma\left(\frac{\nu + 1}{2}\right)}{\sqrt{\nu\pi}\Gamma\left(\frac{\nu}{2}\right)}\left(1+\frac{t^2}{\nu}\right)^{-\frac{\nu+1}{2}}
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\( \nu \)</span> denotes degrees of freedom. The t-distribution resembles the normal distribution but has heavier tails, meaning it is more prone to producing values that fall far from its mean. This property makes it particularly useful in hypothesis testing and constructing confidence intervals when the sample size is small. As the sample size increases, the t-distribution approaches the normal distribution, illustrating the connection between them.</p>
<p>The Student’s t-distribution is particularly useful when dealing with small sample sizes or when the population variance is unknown. It is defined as the distribution of the ratio of a standard normal random variable <span class="math notranslate nohighlight">\(Z\)</span> (with mean 0 and variance 1) and the square root of a chi-square random variable <span class="math notranslate nohighlight">\(X\)</span> divided by its degrees of freedom <span class="math notranslate nohighlight">\(v\)</span>, i.e.,</p>
<div class="amsmath math notranslate nohighlight" id="equation-12a13268-df0c-47b4-8c51-81e58d9bd0fa">
<span class="eqno">(1.35)<a class="headerlink" href="#equation-12a13268-df0c-47b4-8c51-81e58d9bd0fa" title="Permalink to this equation">#</a></span>\[\begin{equation}
T = \frac{Z}{\sqrt{X/v}}
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(Z\)</span> follows a standard normal distribution and <span class="math notranslate nohighlight">\(X\)</span> follows a chi-square distribution with <span class="math notranslate nohighlight">\(v\)</span> degrees of freedom. The resulting <span class="math notranslate nohighlight">\(T\)</span> follows a Student’s t-distribution with <span class="math notranslate nohighlight">\(v\)</span> degrees of freedom.</p>
<p>This distribution is symmetric and bell-shaped like the normal distribution but has heavier tails, meaning it is more prone to producing values that fall far from its mean. This property makes the t-distribution particularly suitable for small sample sizes, as it accounts for the increased uncertainty that comes with fewer observations.</p>
<p>The t-distribution is central to many statistical tests, including the t-test for assessing the statistical significance of the difference between two sample means, the construction of confidence intervals for the mean of a normally distributed population when the standard deviation is unknown, and in linear regression analysis.</p>
<p>The relationship between the normal distribution, the chi-square distribution, and the t-distribution highlights the importance of understanding how distributions can be related and transformed into each other, providing a powerful framework for statistical inference.</p>
<p><strong>Exponential distribution</strong></p>
<p>The exponential distribution models the time between events in processes with a constant rate of occurrence and is pivotal in reliability analysis and queuing theory. Its memoryless property implies that the probability of an event occurring in the next instant is independent of how much time has already elapsed. The PDF is</p>
<div class="amsmath math notranslate nohighlight" id="equation-1be0e2bd-4195-4d82-909b-b912185ea308">
<span class="eqno">(1.36)<a class="headerlink" href="#equation-1be0e2bd-4195-4d82-909b-b912185ea308" title="Permalink to this equation">#</a></span>\[\begin{equation}
    f(x;\lambda) = \lambda e^{-\lambda x}
\end{equation}\]</div>
<p>for <span class="math notranslate nohighlight">\( x \geq 0 \)</span>. This distribution describes the time until an event like failure or arrival occurs and is widely used in survival analysis and reliability engineering.</p>
<p><strong>Binomial distribution</strong></p>
<p>The binomial distribution is fundamental in modeling binary outcomes and represents the number of successes in a fixed number of independent Bernoulli trials. The PDF is</p>
<div class="amsmath math notranslate nohighlight" id="equation-fd0bf228-dd4c-4add-9a4d-9dc4aa934432">
<span class="eqno">(1.37)<a class="headerlink" href="#equation-fd0bf228-dd4c-4add-9a4d-9dc4aa934432" title="Permalink to this equation">#</a></span>\[\begin{equation}
    f(k;n,p) = \binom{n}{k}p^k(1-p)^{n-k}
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\( k \)</span> is the number of successes, <span class="math notranslate nohighlight">\( n \)</span> the number of trials, and <span class="math notranslate nohighlight">\( p \)</span> the probability of success. The shape of the binomial distribution can be symmetric or skewed depending on the values of <span class="math notranslate nohighlight">\( n \)</span> and <span class="math notranslate nohighlight">\( p \)</span>. It is extensively used in scenarios like quality control, survey analysis, and clinical trials, providing a model for situations where outcomes are binary and probabilistically independent.</p>
</section>
<section id="hypothesis-testing-framework">
<h2><span class="section-number">1.6. </span>Hypothesis testing framework<a class="headerlink" href="#hypothesis-testing-framework" title="Link to this heading">#</a></h2>
<p>Hypothesis testing is a fundamental framework in statistics used to determine whether there is enough evidence in a sample of data to infer that a certain condition holds for the entire population. In hypothesis testing, two contradictory hypotheses about a population parameter are considered: the null hypothesis (<span class="math notranslate nohighlight">\(H_0\)</span>) and the alternative hypothesis (<span class="math notranslate nohighlight">\(H_1\)</span>). The null hypothesis represents a default position or a statement of no effect or no difference. The alternative hypothesis represents what we want to prove or establish. A test statistic is calculated from the sample data and is used to assess the truth of the null hypothesis. The choice of test statistic depends on the nature of the data and the hypothesis being tested. The P-value is the probability of observing a test statistic as extreme as, or more extreme than, the observed value under the assumption that the null hypothesis is true. A smaller P-value indicates that the observed data is less likely under the null hypothesis. Based on the P-value and a predetermined significance level (usually denoted as <span class="math notranslate nohighlight">\(\alpha\)</span>, commonly set at 0.05), a decision is made: if the P-value is less than <span class="math notranslate nohighlight">\(\alpha\)</span>, the null hypothesis is rejected in favor of the alternative hypothesis; if the P-value is greater than <span class="math notranslate nohighlight">\(\alpha\)</span>, there is not enough evidence to reject the null hypothesis. In hypothesis testing, two types of errors can occur. Type I error corresponds to ejecting the null hypothesis when it is actually true (false positive). The probability of making a Type I error is <span class="math notranslate nohighlight">\(\alpha\)</span>. Type II error is failing to reject the null hypothesis when the alternative hypothesis is true (false negative). Hypothesis testing is a critical tool in statistics for making inferences about populations based on sample data. It allows researchers to test assumptions and make decisions based on statistical evidence. The goal of hypothesis testing is not to prove the null hypothesis but to assess the strength of evidence against it.</p>
<p><strong>Using distributions for hypothesis tests</strong></p>
<p>Hypothesis testing is a foundational concept in statistics used to infer the properties of a population based on sample data. The choice of distribution for conducting a hypothesis test depends on the nature of the data, the size of the sample, and the assumptions that can be made about the population. Below, we explore various hypothesis tests, the distributions used, and the rationale for their use.</p>
<p><strong>Comparing means</strong></p>
<ul class="simple">
<li><p>The <strong>Z-test</strong> is used when comparing the mean of a sample to a known population mean, or comparing the means of two large independent samples. The Z-test is applicable when the population variance is known and the sample size is large (typically <span class="math notranslate nohighlight">\(n &gt; 30\)</span>). The normal distribution is used due to the CLT, which states that the sampling distribution of the sample mean will approximate a normal distribution as the sample size becomes large, regardless of the population’s distribution.</p></li>
<li><p>The <strong>T-test</strong> is used when the population variance is unknown and the sample size is small, the t-distribution is used. The t-test is more accommodating of the uncertainty in the sample estimate of the variance, providing more accurate confidence intervals and p-values. The t-distribution converges to the normal distribution as the sample size increases.</p>
<ul>
<li><p><strong>One-sample t-test</strong> compares the mean of a single sample to a known mean.</p></li>
<li><p><strong>Two-sample t-test</strong> compares the means of two independent samples.</p></li>
<li><p><strong>Paired t-test</strong> compares means from the same group at different times or under different conditions.</p></li>
</ul>
</li>
</ul>
<p><strong>Comparing variances</strong>: the <strong>F-test</strong> is used in the analysis of variance (ANOVA) and for comparing the variances of two samples. The F-distribution arises naturally when comparing the ratio of two variances, each of which follows a chi-squared distribution when the underlying population is normally distributed. The F-test assesses whether the groups have the same variance, an assumption often required in ANOVA and regression analysis. ANOVA is used to compare the means of three or more samples. The F-distribution is used in ANOVA to compare the ratio of the variance explained by the model to the variance within the groups. This test helps to determine if there are significant differences between the means of the groups.</p>
<p>In <strong>Regression analysis</strong>, the goal is to model the relationship between one or more independent variables and a dependent variable. Several tests can be employed:</p>
<ul class="simple">
<li><p>\textit{t-tests for regression coefficients:} To determine if individual predictors are significantly related to the dependent variable, t-tests are used, leveraging the t-distribution. This is because the estimates of the coefficients have distributions that are best modeled by the t-distribution, especially with small sample sizes.</p></li>
<li><p>\textit{F-test for Overall Model Significance:} The F-test is used to assess whether at least one predictor variable has a non-zero coefficient, indicating that the model provides a better fit to the data than a model with no predictors. This test uses the F-distribution, comparing the model’s explained variance to the unexplained variance.</p></li>
</ul>
<p><strong>Goodness of fit and independence tests</strong></p>
<ul class="simple">
<li><p>The <strong>chi-squared test</strong> is used for categorical data to assess how likely it is that an observed distribution is due to chance. It is used in goodness-of-fit tests to compare the observed distribution to an expected distribution, and in tests of independence to evaluate the relationship between two categorical variables in a contingency table. The chi-squared distribution is used because the test statistic follows this distribution under the null hypothesis.</p></li>
<li><p><strong>Non-parametric tests</strong> can be used when the assumptions about the population distribution are not met. These tests do not rely on the normality assumption and often use ranking methods or resampling techniques. Examples include the Mann-Whitney U test, Wilcoxon signed-rank test, and Kruskal-Wallis H test.</p></li>
</ul>
<p>## Bayesian learning</p>
<p>Statistical methods can be broadly divided into two macro-categories: frequentist and Bayesian. The frequentist approach views parameters as fixed but unknown quantities; uses data to estimate these parameters; and makes point estimates (i.e., a single best guess) for these parameters. The Bayesian approach views parameters as random variables; uses data and prior beliefs (prior distributions) to update our beliefs about these parameters; and results in a probability distribution over the parameters, capturing the uncertainty. Another difference is that Bayesian statistics treats probability as a measure of belief or certainty rather than frequency. This means probabilities are subjective and can be updated as new information becomes available. In frequentist statistics, probability is interpreted as the long-run frequency of events. It relies on the concept of an infinite sequence of repeated trials. Bayesian methods incorporate prior knowledge or beliefs through the use of prior probability distributions, while in frequentist methods all inferences are made solely from the data at hand.</p>
<p>The Bayesian approach is formalized using Bayes’ theorem:</p>
<div class="amsmath math notranslate nohighlight" id="equation-fa9e2e68-3e74-4880-9844-9590b92be570">
<span class="eqno">(1.38)<a class="headerlink" href="#equation-fa9e2e68-3e74-4880-9844-9590b92be570" title="Permalink to this equation">#</a></span>\[\begin{equation}
    P(\theta | X) = \frac{P(X | \theta)P(\theta)}{P(X)}
\end{equation}\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(\theta | X)\)</span> is the posterior distribution of the parameters given the data.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(X | \theta)\)</span> is the likelihood of the data given the parameters. It represents the probability of observing the data <span class="math notranslate nohighlight">\(X\)</span> given a particular set of parameters <span class="math notranslate nohighlight">\(\theta\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(\theta)\)</span> is the prior distribution of the parameters (our beliefs before seeing the data).</p></li>
<li><p><span class="math notranslate nohighlight">\(P(X)\)</span> is the evidence or marginal likelihood. It is the probability of the data over all possible parameter values, which acts as a normalizing constant to ensure the posterior distribution sums (or integrates) to 1.</p></li>
</ul>
<p>Bayes’ Theorem allows us to update our initial beliefs or probabilities <span class="math notranslate nohighlight">\(P(\theta)\)</span> in light of new evidence (<span class="math notranslate nohighlight">\(X\)</span>). In other words, it provides a way to revise existing predictions or hypotheses given new or additional information. Computing the posterior distribution means determining the probability distribution of the parameters of a model given the observed data. In a Bayesian context, this means updating our beliefs about possible parameter values based on the evidence provided by the data. When we say ``computing the posterior distribution’’, we are essentially trying to determine <span class="math notranslate nohighlight">\(P(\theta | X)\)</span> for all possible values of <span class="math notranslate nohighlight">\(\theta\)</span>. The main challenge in Bayesian learning is computing the posterior distribution, especially for complex models. This is where methods like Markov chain Monte Carlo (MCMC) come into play. Because of these challenges, we often resort to methods like sampling (e.g., MCMC) or approximations to estimate the posterior distribution, rather than computing it exactly. The goal is to get a representation of the distribution that lets us make informed decisions about the likely values of the parameters given the data.</p>
<p>Estimating the posterior distribution is the core of Bayesian inference. After observing data, we combine our prior beliefs with the likelihood of the observed data to compute the posterior distribution. The shape of this distribution reflects our updated beliefs about the parameters given the data. Once we have the posterior distribution, we can draw samples from it. Each sample represents a plausible value of the parameter(s) given our prior beliefs and the observed data. By looking at the spread and distribution of these samples, we can understand the uncertainty associated with our estimates. In many situations, especially with complex models, the posterior distribution might not have a simple analytical form. In these cases, we cannot just ``look’’ at the posterior directly. Instead, we use sampling techniques (like MCMC methods) to draw samples from the posterior, even if we cannot describe the posterior in a simple equation. These samples then serve multiple purposes:</p>
<ul class="simple">
<li><p>Uncertainty estimation: The spread and distribution of the samples give a sense of how uncertain we are about our parameter estimates.</p></li>
<li><p>Predictive modeling: We can use the samples to make predictions for new data and to get a sense of uncertainty in those predictions.</p></li>
<li><p>Model checking: We can compare the predictions of our model (using the posterior samples) to the actual observed data to see if our model is a good fit.</p></li>
<li><p>Decision making: In practical scenarios, decisions might be based on the posterior samples, especially when we need to consider the uncertainty in our estimates.</p></li>
</ul>
<p>So, in summary, while the posterior distribution encapsulates our updated beliefs after seeing data, sampling from the posterior allows us to quantify, explore, and make decisions based on the uncertainty in those beliefs.</p>
</section>
<section id="markov-chain-monte-carlo-mcmc">
<h2><span class="section-number">1.7. </span>Markov chain Monte Carlo (MCMC)<a class="headerlink" href="#markov-chain-monte-carlo-mcmc" title="Link to this heading">#</a></h2>
<p>MCMC algorithms are used to approximate complex probability distributions. They are especially useful in Bayesian statistics when direct computation of the posterior distribution is challenging. The basic idea is that we want to understand a complex distribution, which is too intricate to tackle directly. Instead of trying to compute it exactly, we generate samples that come from that distribution. Over time, the distribution of these samples will closely match your target distribution. The key concepts of MCMC are two. A Markov chain is a sequence of random samples where each sample depends only on the one before it. It is like a random walk where each step is influenced only by the current position. Monte Carlo is a technique where we use random sampling to get numerical results for problems that might be deterministic in principle. The name originates from the Monte Carlo Casino, as it relies on randomness. The main steps of MCMC algorithms are:</p>
<ul class="simple">
<li><p>Initialization: Start at a random position (a random parameter value).</p></li>
<li><p>Proposal: At each step, propose a new position based on the current one. This can be a random jump, but it is typically a small move.</p></li>
<li><p>Acceptance: Decide whether to move to the proposed position. If the new position is a better fit to the data (higher posterior probability*), we will likely accept it. If it is worse, you might still accept it but with a lower probability. This decision process ensures you explore the whole space but spend more time in high-probability areas.</p></li>
<li><p>Iteration: Repeat the proposal and acceptance steps many times. The more steps, the better your approximation will be.</p></li>
<li><p>Burn-In: The initial samples might not be representative because the chain might start far from a high-probability area. So, we will discard an initial set of samples, a process called ``burn-in’’.</p></li>
</ul>
<p>How do we determine if the posterior distribution is higher if we do not have an analytical form? This is the key idea behind MCMC methods (like the Metropolis-Hastings algorithm). We do not need to know the exact value of the posterior distribution; we only need to know it up to a constant of proportionality. In many cases, while the full posterior is hard to compute (due to the difficulty in calculating the normalization constant), its unnormalized version is computable. Remember the basic Bayes’ formula</p>
<div class="amsmath math notranslate nohighlight" id="equation-47a85c57-ee46-4a34-a769-349cf0aa6932">
<span class="eqno">(1.39)<a class="headerlink" href="#equation-47a85c57-ee46-4a34-a769-349cf0aa6932" title="Permalink to this equation">#</a></span>\[\begin{equation}
    \text{posterior} \propto \text{likelihood} \times \text{prior}
\end{equation}\]</div>
<p>In many applications, we can compute the product of the likelihood and the prior for any given set of parameters, but we might not be able to easily normalize it to get a true probability distribution. So, when deciding whether to accept a new proposed position in MCMC, we first compute the unnormalized posterior at the current position (which is the product of the likelihood and the prior). Then we compute the unnormalized posterior at the proposed new position. Finally, we compare these values. If the unnormalized posterior is higher at the new position, then it means the true posterior is also higher there.
Even if we cannot say exactly what the posterior value is at that position, we can still determine if it is higher or lower than at the current position. This relative comparison, rather than an absolute value, is what drives the decision to accept or reject the new proposed position. For the case where the proposed position has a lower unnormalized posterior value, the Metropolis-Hastings algorithm provides a rule to accept it with a probability proportional to the ratio of the unnormalized posteriors (proposed to current). This ensures exploration of the entire parameter space, preventing the algorithm from getting stuck in local modes. In essence, MCMC is a systematic way to ``wander around’’ in a parameter space to understand a probability distribution, especially when direct computation is difficult or impossible. Why MCMC methods are useful:</p>
<ul class="simple">
<li><p>Complex models: Many models (especially in Bayesian settings) result in posterior distributions that are hard to describe and compute. MCMC provides an approach to explore these distributions without needing an analytical solution.</p></li>
<li><p>Flexibility: MCMC can be applied to a wide range of problems. Different MCMC algorithms (like Metropolis-Hastings, Gibbs Sampling, Hamiltonian Monte Carlo) are suited to different types of problems.</p></li>
<li><p>Uncertainty: By generating samples from the posterior, MCMC gives a way to understand and quantify uncertainty in parameter estimates.</p></li>
</ul>
<p><strong>Maximum a posterior estimation (MAP)</strong></p>
<p>When training a model using <span class="math notranslate nohighlight">\(n\)</span> examples, we have a parameter vector <span class="math notranslate nohighlight">\(\theta\)</span> (e.g., all the weights and biases of a neural network); a prior distribution <span class="math notranslate nohighlight">\(p(\boldsymbol{\theta})\)</span> (e.g., we might assume the weights in a neural network are normally distributed around zero); the likelihood <span class="math notranslate nohighlight">\(p(\mathbf{x}|\boldsymbol{\theta})\)</span> (i.e., the probability of data item <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> given our model parameterized by <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>. It tells us how well our model with parameters <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> explains the observed data). We can define the (unnormalized) posterior as</p>
<div class="amsmath math notranslate nohighlight" id="equation-743c2cc8-3108-459e-9f98-8c711dd8b5a0">
<span class="eqno">(1.40)<a class="headerlink" href="#equation-743c2cc8-3108-459e-9f98-8c711dd8b5a0" title="Permalink to this equation">#</a></span>\[\begin{equation}
    p(\boldsymbol{\theta}|\mathbf{X}) \propto p(\boldsymbol{\theta}) \prod_{i=1}^{n} p(\mathbf{x}_i|\boldsymbol{\theta})
\end{equation}\]</div>
<p>The objective in optimization is often to find the MAP estimate of the parameters, <span class="math notranslate nohighlight">\(\boldsymbol{\theta}*\)</span>. The MAP estimate is the value of <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> that maximizes the posterior distribution. In machine learning, the MAP estimate is often used in the context of Bayesian models, where the goal is to find the most probable parameter setting (or hypothesis) given the observed data and prior beliefs. The MAP estimate can be thought of as a compromise between the maximum likelihood estimate (MLE), which only considers the likelihood, and the full Bayesian approach, which considers the entire posterior distribution. In the optimization context, we have that</p>
<ul class="simple">
<li><p>The prior acts as a regularizer. A regularizer is a term added to a cost or loss function to discourage certain parameter values or configurations. For instance, a prior that prefers smaller values of <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> would act like an L2 regularization.</p></li>
<li><p>The likelihood terms <span class="math notranslate nohighlight">\(p(\mathbf{x}_i|\boldsymbol{\theta})\)</span> make up the cost function. The goal is to adjust <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> so that the model explains the observed data well, i.e., maximizes the likelihood.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Applied Causal Inference for Electricity Markets</p>
      </div>
    </a>
    <a class="right-next"
       href="review_linear_models.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">2. </span>Linear Regression</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-concepts">1.1. Basic concepts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#expectation-variance-and-covariance">1.2. Expectation, variance, and covariance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convergence-and-estimation">1.3. Convergence and estimation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-prediction">1.4. Statistical prediction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#main-probability-distributions">1.5. Main probability distributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hypothesis-testing-framework">1.6. Hypothesis testing framework</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#markov-chain-monte-carlo-mcmc">1.7. Markov chain Monte Carlo (MCMC)</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Davide Cacciarelli
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>